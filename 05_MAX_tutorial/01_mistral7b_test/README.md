# Result

- https://github.com/modularml/max

  - https://github.com/modularml/max/tree/main/examples/inference/mistral7b-python-onnx

- Run your first model

  - Let's start with something boring, similar to a "Hello world," just to make sure MAX Engine is working.

  - First, clone the code examples:

  ```bash
  git clone https://github.com/modularml/max.git

  cd max/examples/inference/mistral7b-python-onnx
  ```

```bash

python3 -m pip install -r requirements.txt

./run.sh

```
